# DeepLog

https://github.com/wuyifan18/DeepLog

https://www.cs.utah.edu/~lifeifei/papers/deeplog.pdf


ページ1
DeepLo​​g：システムログからの異常の検出と診断ディープラーニングを通じて


ページ1
DeepLo​​g：システムログからの異常の検出と診断ディープラーニングを通じてMin Du、Feifei Li、Guinn Zheng、Vivek Srikumarユタ大学コンピューティング学部1mind、lifeifei、guineng、svivekl @ cs.utah.edu概要異常検出は、安全で安全なシステムを構築するための重要なステップです。信頼できるシステム。システムログの主な目的は、さまざまな重要なポイントでシステムの状態と重要なイベントを記録するシステム障害のデバッグと根本原因分析の実行に役立ちます。そのようなログデータは、ほぼすべてのコンピューターシステムで普遍的に利用できます。ログデータは、理解するための重要で貴重なリソースですシステムのステータスとパフォーマンスの問題。したがって、さまざまなシステムtemログは、当然のことながら、オンラインの優れた情報源です。監視と異常検出。DeepLo​​gを提案します。Long Short-Term Memory（LSTM）を利用したニューラルネットワークモデルシステムログを自然言語シーケンスとしてモデル化します。許可されていますDeepLo​​gは、通常の実行からログ領域を自動的に学習します。ログの範囲がモデルから逸脱したときに異常を検出する通常の実行でログデータからトレーニングされます。また、DeepLo​​gモデルを段階的に更新する方法を示します時間の経過とともに新しいログパネルに適応できるオンラインファッション。さらに、DeepLo​​gコンストラクトは、基礎となる異常が検出されると、ユーザーが診断できるようにシステムログ検出された異常と根本原因分析を効果的に実行します。大きなログデータに対する広範な実験的評価により、DeepLo​​gが他の既存のログベースの異常を上回ったこと従来のデータマイニング手法に基づく検出方法。CCSの概念•情報システム→オンライン分析処理。•セキュリティとプライバシー→侵入/異常検出とマルウェアのミティガション;キーワード異常検出; 深層学習; ログデータ分析。1はじめに異常検出は、安全なシステムを構築するための重要なタスクです信頼できるコンピュータシステム。システムおよびアプリケーションとしてこれまで以上にますます複雑になり、それらは主題です敵が悪用する可能性のあるより多くのバグや脆弱性へACKを起動します。このような攻撃はますます年を重ねています洗練された。その結果、異常検出はより多くなりましたこの作品の全部または一部の個人または個人向けのデジタルまたはハードコピーを作成する許可コピーを作成または配布しない限り、教室での使用は無料で許可されます営利または商業上の利点のため、そのコピーにはこの通知と完全な引用が含まれます最初のページに。ACM以外が所有するこの作品のコンポーネントの著作権尊敬されなければならない。クレジットによる抽象化は許可されています。それ以外の場合、または再発行するには、サーバーに投稿したり、リストに再配布したりするには、事前の特定の許可および/または費用。permissions@acm.orgから権限をリクエストします。CCS'17、10月30日〜11月。2017年3月、米国テキサス州ダラス。©2017 ACM。ISBN 978-1-4503-4946-8 / 17/10。。。$ 15.00DOI：hp：//dx.doi.org/10.1145/3133956.3134015挑戦的で多くの伝統的な異常検出方法に基づく標準のマイニング手法ではもはや効果的ではありません。システムログには、さまざまなシステム状態と重要なイベントが記録されますパフォーマンスの問題と障害のデバッグに役立つ重要なポイント、および根本原因分析を実行します。このようなログデータは、広く利用可能ですほぼすべてのコンピュータシステムで使用され、システムステータスの理解。さらに、システムログはアクティブに実行中のプロセスから発生する注目すべきイベントオンライン監視のための優れた情報源です異常検出。異常のシステムログデータを活用する既存のアプローチ検出は大きく3つのグループに分類できます：PCAベースログメッセージカウンターに対するアプローチ[ 39]、不変マイニングベース異なるログ間の共起領域を取得する方法キー[21 ]、および実行異常を識別するための方法に基づく方法プログラムロジックows [ 42]にあります。彼らは成功しているにもかかわらず特定のシナリオ、それらのどれも普遍的な異常として有効ではありません異なる攻撃を防ぐことができる検出方法オンラインファッション。は、DomLogを提案しています。大量のシステムログを活用する検出。eDeepLo​​gの設計の背後にある主要な直観は、自然言語からのものです。ゲージ処理：ログエントリをシーケンスの要素と見なしますそれは特定の文法と規則に従います。確かに、システムtem logは、厳密な一連のプログラムに従うプログラムによって生成されます。論理と制御は、自然言語に非常に似ています。（ただし、語彙はより構造化され、制限されています）。そのために、DeepLo​​gは、この一連のログをモデル化するディープニューラルネットワークです。Long Short-Term Memory（LSTM）を使用したエントリ[18 ]。許可されていますDeepLo​​gは、ログのモデルを自動的に学習します。不正な実行と通常のシステム実行からのag偏差異常として。さらに、学習主導のアプローチであるため、DeepLo​​gモデルを段階的に更新して、時間の経過とともに出現する新しいログパネルに適応できます。挑戦。ログデータは構造化されておらず、その形式と形式はmanticsは、システムごとに大きく異なる可能性があります。もう非構造化ログを使用して問題を診断することも困難エラーが発生したことを知っているユーザー[ 43] ; オンライン異常検出大量のログデータからの取得はさらに困難です。既存のメソッドはルールベースのアプローチを使用してこの問題に対処します。特定のドメイン知識[41 ]が必要です。たとえば、次のような機能を使用しますログを解析するための「IPアドレス」。ただし、これは一般的には機能しません知ることがほとんど不可能である目的の異常検出さまざまなタイプのログの興味深い機能をアプリオリに（そして異なるタイプのacksから保護するため）。異常検出は、有用であるためにタイムリーでなければなりません。ユーザーは進行中の確認またはシステムパフォーマンスに介入できます問題[10 ]。決定はストリーミング方式で行われます。なので
ページ2
結果として、複数のパスを実行する必要があるo ineメソッドログデータ全体は、私たちのセッシングには適用されません[ 22、39 ]。我々未知の種類の異常を検出できるようになりたい特定の種類の異常を対象とするのではなく、したがって、正常と異常の両方を使用する以前の作品[ 44]（特定の異常の種類）バイナリ分類器を訓練するためのログデータエントリ異常検出は、このコンテキストでは役に立ちません。もう1つの課題は、並行性にあります。明らかに、or-ログ内のログメッセージのderは、診断と分析（たとえば、プログラム）。ただし、多くのシステムログでは、ログメッセージが生成されますいくつかの異なるスレッドまたは同時に実行中のタスクによって。そのような並行性により、作業フローに基づく異常の適用を困難にする単一のタスクにワークフローモデルを使用する検出方法[ 42 ]ログメッセージのシーケンスと照合する生成モデルとして。最後に、各ログメッセージにはログなどの豊富な情報が含まれていますキーと1つ以上のメトリック値、およびそのタイムスタンプ。あこれらの異なる部分を統合して利用する全体的なアプローチより多くの情報がより効果的になります。ほとんどの既存の方法[ 22、32、 39、41、42、44]ログメッセージの唯一の特異C部分を分析（ログログなど）できる異常のタイプを制限します検出。私たちの貢献。リカレントニューラルネットワーク（RNN）は、ループを使用して最後の出力を転送するcialニューラルネットワーク状態を現在の入力に反映するため、事前に履歴を追跡して辞書。長い短期メモリ（LSTM）ネットワーク[13 、 18、27]長期的に記憶する能力を持つRNNのインスタンスですシーケンスに対する依存関係。LSTMは成功を実証しています機械翻訳[ 35 ]、感情分析などのさまざまなタスクでsis [8 ]、および医学的自己診断[20]。システムログのエントリは構造化ソースの実行によって生成されるイベントのシーケンスコード（したがって、構造化言語と見なすことができます）を設計します。オンラインのLSTMニューラルネットワークを使用したDeepLo​​gフレームワークシステムログの異常検出。DeepLo​​gはログだけでなくキーだけでなく、異常検出のためのログエントリのメトリック値、したがって、さまざまな種類の異常をキャプチャできます。DeepLo​​gシーケンスで構成される小さなトレーニングデータセットにのみ依存する「通常のログエントリ」の。トレーニングフェーズでは、DeepLo​​gは通常のログシーケンスを認識し、オンライン異常に使用できますストリーミング方式での受信ログエントリの検出。直感的に、DeepLo​​gは潜在的に非からのログエントリ間の線形および高次元の依存関係通常のシステム実行パスに対応するトレーニングデータ。異常が特定されたときにユーザーが問題を診断できるようにするには、また、DeepLo​​gは、その間にログエントリから作業モデルを構築します。トレーニング段階。DeepLo​​gは、concur-によって生成されたログエントリを分離します。タスクまたはスレッドを異なるシーケンスにレンタルして、作業ができるようにするモデルは、個別のタスクごとに作成できます。私たちの評価は、調査した大規模なHDFSログデータセットで前作[22により、ごくわずかな部分で訓練39]、（1％未満）通常のシステム実行に対応するログエントリ、DeepLo​​gは、ほぼ100％の検出精度を達成できます。ログエントリの残りの99％。大規模なOpenStackの結果ログは同様の傾向を伝えます。さらに、DeepLo​​gはまた提供します検出中に重みを段階的に更新する機能ライブのユーザーフィードバックを組み込むことによる初期化フェーズ。より具体的には、DeepLo​​gは、通常のログの場合、ユーザーフィードバックのメカニズムを提供しますエントリは異常として誤って分類されます。その後、DeepLo​​gは重みをオンラインで動的に調整するフィードバック新しいシステムの実行（したがって、新しいログ）のパターンに適応する。2予選2.1ログパーサーまず、非構造化フリーテキストログエントリを解析して構造化表現、これでシーケンシャルモデルを学ぶことができます構造化データ。いくつかの従来の研究[9で示されるように22、39、42、45]、効果的な方法は、「ログキー」（別名「メッセージタイプ」）各ログエントリから。ログエントリのログキーeソースのprintステートメントからの文字列constantkを参照しますそのコードの実行中に印刷されたコード。例えば、ログエントリeのログキー k = 「インスタンスを構築するのに10秒かかりました。」ですk = インスタンスの構築に*秒かかりました。、からの文字列定数ですprintステートメントprintf（ "％f秒かけてインスタンスを構築します。"、t）。注意パラメータがログキーのアスタリスクとして抽象化されていること。eseメトリック値は、基になるシステムの状態とパフォーマンスを反映します状態。特定のパラメータの値は、HDFSログのblock_idなどの特定の実行シーケンスOpenStackログのinstance_id。これらのIDはグループ化できますログエントリを一緒にするか、同時実行によって生成されたログエントリを解く分離する工程、単一スレッドシーケンシャル配列[ 22、 39、42、 45]。最先端のログ解析方法は、Spell [9 ]、着信を解析する教師なしストリーミングパーサーLCS（最長の共通サブシーケンス）。ログ分析に過去の仕事[ 22、 39、42、44] times-捨てましたログエントリのタンプおよび/またはパラメータ値、および使用されたログキーのみ異常を検出します。DeepLo​​gは各ログのパラメータ値を保存しますエントリe、およびeとその前身との間の経過時間、ベクトルへ→→ e。ベクトルは、DeepLo​​gに加えて使用されます。ログキー。例を表1に示します。複数のラウンドからのログエントリのシーケンスの結果をOpenStackでの仮想マシン（VM）削除タスクの実行。2.2 DeepLo​​gのアーキテクチャと概要DeepLo​​gの電子アーキテクチャは、図に示されている1三つの主要とコンポーネント：ログキーの異常検出モデル、パラメーターター値異常検出モデル、およびワークフローモデル検出された異常を診断します。トレーニング段階。DeepLo​​gのトレーニングデータは、通常のシステム実行パス。各ログエントリはログキーに解析されますおよびパラメータ値ベクトル。eから解析されたログキーシーケンストレーニングログファイルは、DeepLo​​gでログキー異常のトレーニングに使用されます。tectionモデル、およびシステム実行作業owモデルを構築する診断目的のため。異なるキーkごとに、DeepLo​​gもトレーニングしますシステムパフォーマンスの異常を検出するためのモデルを維持しますパラメータ値によってトレーニングされた、これらのメトリック値によって反映されるkのベクトルシーケンス検出ステージ。新しく到着したログエントリがログに解析されますキーとパラメータ値ベクトル。DeepLo​​gは最初にログキーを使用します
3ページ
ログメッセージ（下線付きのログキー）ログキーパラメータ値ベクトルt 1 le1の削除が完了しましたk 1[t 1 − t 0、le1Id]T 2はかかっ0.61割り当て解除ネットワークに秒を...k 2[T 2 - T 1、0.61]t 3 VMが停止しました（ライフサイクルイベント）k 3[t 3 − t 2 ]………表1：OpenStack VM削除タスクのログエントリ。T雨にg SタゲD選択Sタゲログキー異常検出モデル……パラメータ値異常検出モデル各ログキーワークフロー通常の実行ログファイルログパーサー……………………各ログエントリ=ログキー+パラメータ値ベクトル新しいログエントリログパーサーパラメータ値ベクトル+モデルのトレーニングワークフローを構築する異常？はい番号、小切手ベクター異常？はい診断更新モデルなら偽陽性ログキーTラーにメートルodels番号図1：DeepLo​​gアーキテクチャ。着信ログキーが正常。はいの場合、DeepLo​​gはさらにパラメータ値ベクトルをチェックしますそのログキーのパラメータ値異常検出モデルを使用します。新しいエントリは、ログキーまたはそのパラメーター値ベクトルは異常であると予測されます。最後に、異常であるというラベルが付けられている、DeepLo​​gの作業フローモデルは、ユーザーが異常を診断するための意味情報。実行パターンは時間の経過とともに変化するか、元のバージョンに含まれていなかった可能性がありますトレーニングデータ。DeepLo​​gには、ユーザーを収集するためのオプションも用意されていますフィードバック。ユーザーが検出された異常を誤検知として報告した場合、DeepLo​​gは、増分更新するためのラベル付きレコードとしてそれを使用できます新しいモデルを組み込んで適応するためのモデル。2.3 ReatモデルDeepLo​​gは、包括的で複雑な相関関係を学習し、通常によって生成された一連のログエントリに埋め込まれたパターンシステム実行パス。以降、システムログは彼ら自身は安全で保護されており、敵は攻撃することはできませんログ自体の整合性。また、敵対者はシステムのソースコードを変更して、ログの動作を変更し、パネル。言われているように、大まかに言えば、2つのタイプのACKがあります私たちが考えること。（1）システム実行の誤動作を引き起こし、したがってシステムログの異常な部分。たとえば、サービス拒否（DoS）実行が遅くなり、パフォーマンスが低下する可能性があるackログのタイムスタンプに影響するマンスの異常パラメータ値ベクトルシーケンス。繰り返しを引き起こすACKブラインドリターン指向プログラミング（BROP）などのサーバーの再起動サーバーの再起動ログキーが多すぎると表示されるack [ 5]。そして、対応するログがシーケンスが早期に終了するか、例外ログエントリが表示されます。（2）のためにシステムログにトレースを残す可能性があるackシステム監視サービスの活動を記録します。例は侵入検知システム（IDS）によってログに記録された不審なアクティビティ。3異常検出3.1実行パスの異常まず、実行パスの異常を検出する方法について説明しますログキーシーケンス。個別の印刷ステートメントの総数から（ログエントリを出力する）ソースコードの定数は一定なので、合計も個別のログキーの数。K = {k 1、k 2、...、k n }をログ生成システムのソースコードからの個別のログキー。ログエントリがログキーに解析されると、ログキーシーケンスその特定の実行につながる実行パスを反映しますログ出力ステートメントの順序。m iをログキーシーケンスのi番目のキー。明らかに、m iはKからのn個の可能なキー、および最も依存しているキーm iの前に出現した最近のキー。ログキーシーケンスでの異常検出をマルチクラス分類の問題。それぞれ異なるログキーが定義されます。クラス。DeepLo​​gを最近のマルチクラス分類者としてトレーニングします環境。e入力は最近のログキーの履歴であり、出力はKからのn個のログキーにわたる確率分布。確率シーケンス内の次のログキーは、キーKであることを私 ∈K.は、図2は分類セットアップの要約です。tが次に表示されるログキーのシーケンスID。分類のための入力陽イオンは、h個の最新のログキーのウィンドウwです。現状では、w = {m t−h、...、m t-2、m t−1 }、ここで各m iはKであり、対数ログエントリe iのキー。同じログキーの値がwに数回現れる eトレーニングフェーズの出力は条件付き確率分布Pr [m t = k i | w]のモデル各k iは ∈K（I = 1、...、N）。e検出フェーズでは、このモデルを使用して予測を行い、予測された出力を実際に表示される観測されたログキー値。トレーニング段階。eトレーニング段階はログのごく一部に依存しています基本となるシステムの通常の実行によって生成されるエントリ。トレーニングデータの長さhのログシーケンスごとに、DeepLo​​g
4ページ
DeepLo​​g入力：h最近キーを記録する出力：条件付き確率入力が与えられた次のログキーの最近のシーケンス図2：ログキーの異常検出モデルの概要。K有する確率分布のために、そのモデルを更新するのI ∈Kを次のログキー値として。たとえば、小さなログファイルがあるとします。通常の実行の結果は、一連のログに解析されますキー：{k 22、k 5、k 11、k 9、k 11、k 26 }。ウィンドウサイズh = 3の場合、DeepLo​​gをトレーニングするための入力シーケンスと出力ラベルのペアは次のようになります。{k 22、k 5、k 11 →k 9 }、{k 5、k 11、k 9 →k 11 }、{k 11、k 9、k 11 →k 26 }。検出ステージ。DeepLo​​gは、オンで異常検出を実行しますライン、ストリーミング設定。着信ログキーがm t（解析済み着信ログエントリからe t）は、正常または異常と見なされますmal、w = {m t−h、...、m t−1 }をその入力としてDeepLo​​gに送信します。e出力は確率分布Pr [m t | w] = {k 1：p 1、k 2：p 2、...、k n：p n }は、Kから履歴が与えられると、次のログキー値として表示されます。実際には、複数のログキー値がm tとして表示される場合があります。のためにスタンス、システムがホストに接続するための空の場合、m t「*が応答するのを待っている」または「*に接続されている」のいずれかです。どちらも通常のシステム動作です。DeepLo​​gはそのようなことを学ぶことができなければなりませんトレーニング中のパネル。私たちの戦略は、可能なログをソートすることです確率Pr [m t | w]に基づいてキーKを処理し、キー値を処理しますそれがトップ候補の中にある場合は、通常どおり。ログキーが凝集しているそうでなければ異常な実行からのものとして。3.1.1従来のN-gram言語モデル。e-の問題xedから抽出された一連の単語に確率を刻む語彙は、言語モデリングの古典的な問題であり、広く自然言語処理（NLP）コミュニティによって研究されています[ 24]。私たちの場合、各ログキーは、語彙K. eの典型的な言語モデリングアプローチ確率を任意に長いシーケンスに割り当てることはN-gramです。モデル。e直感は、シーケンス内の特定の単語が全体ではなく、最近の前任者によってのみ影響を受ける歴史。私たちの縫製では、この近似は縫製と同等ですPr（m t = k i | m 1、...、m t−1）= Pr（m t = k i | m t−N、...、m t−1）ここでNは、考慮される最近の履歴の長さを示します。トレーニングでは、相対確率を使用してこの確率を計算できます最大の可能性を与えるために、大きなコーパスからの頻度をカウントします見積り。キーの長いシーケンス{m 1、m 2、...、m t }が与えられると、を使用して、i 番目のキーk iを観察する確率を推定できます。{m t−N、...、m t−1、m t = k i }の相対頻度カウントシーケンス{m t-N、...、m t-1 }を考慮してください。つまり、Pr（m t =k i | m 1、...、m t−1）= count（m t-N、...、m t−1、m t = k i）/ count（m t-N、...、m t−1）。スライドを使用してこれらの周波数をカウントすることに注意してくださいキーシーケンス全体にわたるサイズNのウィンドウ。N-gramモデルを設定に適用するには、Nを次のように使用するだけです。履歴ウィンドウのサイズ、つまり、実験では次の場合にseth = NN-gramモデルが使用されます。hは履歴スライディングウィンドウです。図2に示すサイズ。これをベースライン手法として使用します。3.1.2 LSTMアプローチ。近年、神経言語は再帰型ニューラルネットワークを使用するelsは、さまざまなNLPタスク全体で有効です[ 3、25 ]。Nグラムと比較してLSTMブロック最後の状態の出力転送される現在の入力状態LSTMブロックLSTMブロックDeepLo​​g出力入力LSTMブロックLSTMブロックLSTMブロックロールアウトする積み重ねるLSTMブロックLSTMブロックLSTMブロックLSTMブロック図3：ログキーの異常検出の詳細ビュースタックLSTMを使用したモデル。LSTMベースの言語モデルは、より複雑なパターンをエンコードできます。シーケンスを使い、長距離状態を維持します[34 ]。繁雑システム内の並行タスクからのログエントリとインターリーブtem logは、従来の言語モデルの有効性を低下させる可能性があります。我ら、DeepLo​​gは、異常検出にLSTMニューラルネットワーク[18 ]を使用しますログキーシーケンスから。ログキーのシーケンスが与えられると、LSTMネットワークは、kの確率を最大化するI次のログキー値として∈Kトレーニングデータシーケンスによって反映されます。つまり、学習します確率分布Pr（m t = k i | m t-h、...、m t-2、m t-1）トレーニングログのキーシーケンスの確率を最大化します。図3に設計を示します。グレの上部には、LSTMの再発性を反映する単一のLSTMブロック。各LSTMブロックは、入力の状態をxedのベクトルとして記憶します寸法。e前回からのLSTMブロックの状態ステップは、その（外部）データと共に次の入力にも供給されます入力（この特定の例ではm t-i）、新しい状態を計算すると出力。履歴情報がどのように渡され、単一のLSTMブロックで維持されます。一連のLSTMブロックは、反復のアンロールバージョンを形成します図3の中央に示すように、1つのレイヤーのモデル。各セル隠しベクトルH t-iとセル状態ベクトルC t-iを維持します。どちらも状態を初期化するために次のブロックに渡されます。私たちの場合、入力シーケンスw（aからのログキーごとに1つのLSTMブロックを使用するhログキーのウィンドウ）。したがって、単一のレイヤーはhのアンロールで構成されます。LSTMブロック。単一のLSTMブロック内では、入力（例：m t-i）と前のous出力（H t−i−1）は、（1）以前のセル状態CのT-I-1状態Cの中に保持するT-I 、（2）現在の使用方法状態に影響を与えるための入力と前の出力、および（3）方法出力H t-iを作成します。のセットを使用して達成されますを制御することで状態ダイナミクスを決定するゲーティング機能入力および以前の出力から保持する情報の量、および次のステップに進む情報。各ゲーティング機能学習する重みのセットによってパラメーター化されます。e表現力豊かLSTMブロックの容量は、メモリの数によって決まります
5ページ
単位（つまり、隠れた状態ベクトルHの次元）。のためスペースの制約のため、読者にNLPプライマーを紹介します（例：[ 12]）LSTMの正式な特性評価。eトレーニングステップでは、重みへの適切な割り当てを見つける必要がありますLSTMのシーケンスの最終的な出力は、トレーニングデータセットの入力に付属するsiredラベル（出力）。トレーニングプロセス中、各入力/出力ペアは段階的にこれらの重みを更新します。勾配の設定による損失の最小化により、香り。DeepLo​​gでは、入力はhログキーのウィンドウwで構成されます。出力は、適切なログキー値です。を使用しております訓練のためのカテゴリー的クロスエントロピー損失。erトレーニングが完了したら、入力の出力を予測できます（w = {m t−h、...、m t−1 }）h LSTMブロックのレイヤーを使用します。各ログキー入力wは、このレイヤーの対応するLSTMブロックにフィードします。複数のレイヤーを積み上げて、の対応する各LSTMブロックの入力としての前の層次のレイヤーでは、これは深いLSTMニューラルネットワークになります。図3のブーム。簡単にするために、入力レイヤーと標準のエンコード/デコード方式で構築された出力層。e入力層は、Kからn個の可能なログキーをワンホットとしてエンコードしますベクトル。現状では、疎なn次元ベクトル−→u iが構築されますログキーkに対するI ∈K、例えばthat-→UがI [I] = 1アンド→U I全てに対して[J] = 0その他j i。e出力層は、最終的な隠された状態を次のように変換します。標準多項式を使用した確率分布関数Prを表すロジスティック関数[M T = K iはそれぞれkの| W] I ∈K.図3の例では、非表示になっているのは2つだけです。層ですが、より多くの層を使用できます。3.2パラメータ値とパフォーマンスの異常ログキーシーケンスは、実行パスの異常を検出するのに役立ちます。嘘つき。ただし、一部の異常は、通常の実行パスですが、不規則なパラメーター値として。ese（同じログキーの）パラメータ値ベクトルはパラメータを形成しますter値ベクトルシーケンス、および異なるログからのこれらのシーケンスキーは、多次元の特徴空間を形成します。パフォーマンス監視と異常検出。ベースラインアプローチ。単純なアプローチは、すべてのパラメータを保存することです値ベクトルシーケンスを行列にして、各列がpa-ログキーkからのラメータ値シーケンス（次のことが可能であることに注意してください）パラメータのサイズに応じてkに複数の列がある値ベクトル）。この行列の行iは、時間インスタンスt iを表します。表のログエントリを検討します。例として1。ええこの例の3つの異なるログキー値とそのサイズパラメータ値のベクトルは、それぞれ2、2、1です。したがって、行このマトリックス中の1は、時間インスタンスt表す1値で[T 1、T - 0、le1Id、null、null、null]。同様に、行2と行3は[null、null、T 2 - T 1、0.61、ヌル]および[NULL、NULL、NULL、NULL、T 3 - T 2 ]は、それぞれ。各行に時間インスタンスの範囲を表すように依頼することもできます各行がその中の複数のログメッセージに対応するように時間範囲と疎らになります。しかし、マトリックスは依然として非常に多くのログキー値が存在する場合、または存在する場合はまばらパラメータ値ベクトル。さらに、このアプローチは異常検出プロセスの遅延、およびそれはまた困難です各範囲の長さの適切な値を確認してください。このマトリックスを考えると、多くの有名なデータ駆動型の異常検出主成分分析などの手法が適用できる（PCA）および自己組織化マップ（SOM）。eyは異なるフィーチャディメンション間の相関をキャプチャします。どうやって-これまで、ログデータのコンテキストにおけるこのメソッドの主な制限は、特定の場所で複数のログキーが出現することがある時間インスタンスも同様に可能性があります。たとえば、k 1の次数と表1の k 2は、タスクが同時に実行されるため、任意です。です現象、およびマトリックスがスパースであるという事実により、これらの技術ニークは私たちの生活の中で有効ではありません。最後に、彼らはモデル化することができませんパラメータ値ベクトルシーケンスに存在する自己相関（単一のベクトルシーケンスにおける時間の経過に伴う通常のパターン）。私たちのアプローチ。DeepLo​​gはパラメータ値の異常検出をトレーニングします各パラメータ値のベクトルシーケンスを表示することによるモデル（ログキー）を別の時系列として。表1の例を検討してください。パラメータの時系列OFK TER値ベクトル系列2である：{[T 2 -t 1、0.61]、[T 2−t1、1 ]}。したがって、私たちの問題は、多変量からの異常検出に還元されます時系列データ。LSTMベースのアプローチを適用することが可能です再び。図3に示すような同様のLSTMネットワークを使用して次の調整を使用して、多変量時系列データをモデル化します。メント。パラメータ用に個別のLSTMネットワークが構築されていることに注意してください個別のログキー値の値ベクトルシーケンス。入力。e各タイムステップでの入力は、単にパラメーター値です。そのタイムスタンプからのベクトル。各ベクトルの値を正規化しますからのすべての値の平均と標準偏差トレーニングデータからの同じパラメーター位置。出力。e出力は、予測値としての実数値ベクトルです。パラメータのシーケンスに基づく次のパラメータ値ベクトル最近の履歴からの値ベクトル。トレーニングの目的関数。多変量時系列の場合データ、トレーニングプロセスはそのLSTMの重みを調整しようとします予測と予測の間の誤差を最小限に抑えるためのモデル観測されたパラメーター値のベクトル。私たち、平均二乗損失はトレーニングプロセス中のエラーを最小限に抑えます。異常検出。予測と予測の違い観測されたパラメータ値ベクトルは、平均二乗によって測定されますエラー（MSE）。異常に対して魔法のエラーしきい値を設定する代わりにアドホックな方法で検出目的のために、私たちは列車を分割しますデータを2つのサブセットに変換：モデルトレーニングセットと検証セットする。検証セットの各ベクトル-→に対して、モデルを適用しますトレーニングセットによって生成され、事前辞書（検証でbefore-→からのベクトルシーケンスを使用）セット）and-→。すべてのタイムステップで、予測されたベクトルと検証グループの実際のベクトルは、次のようにモデル化されます。ガウス分布。展開時に、予測とオブジェクト間のエラーが提供された値のベクトルが高水準の信頼区間内にある上記のガウス分布のパラメータ値ベクトル着信ログエントリは正常と見なされ、そうでなければ異常。ログメッセージのパラメータ値は重要な記録であるためシステム状態メトリック、このメソッドは、さまざまなタイプのパフォーマンスの異常。たとえば、パフォーマンスの異常により、「スローダウン」と見なします。DeepLo​​gは各パラメータに保存することを思い出してくださいeter値は、連続するログエントリ間の経過時間を表すベクトルです。e上記のLSTMモデル、パラメーター値ベクトルを多変量時系列は、異常なパターンを1つで検出できます
6ページ
この時系列の次元以上。経過時間の値はそのような次元の1つだけです。3.3異常検出モデルのオンライン更新明らかに、トレーニングデータはすべての可能な通常のエクササイズをカバーしているとは限りません。ションパターン。さらに、システムの動作は時間とともに変化する可能性がありますワークロードとデータの特性によって異なります。したがって、それはDeepLo​​gがLSTMの重みを段階的に更新するために必要新しいログパネルを組み込んで適応するモデル。これをする、DeepLo​​gは、ユーザーがフィードバックを提供するためのメカニズムを提供します。これにより、DeepLo​​gは誤検知を使用して重みを調整できます。にとってたとえば、h = 3で、最近の履歴シーケンスが{k 1、k 2、k 3 }、およびDeepLo​​gは次のログキーを確率付きのk 1であると予測しました能力1、次のログキー値はk 2で、ラベルが付けられます異常として。これが誤検知であるとユーザーが報告した場合、DeepLo​​g次の入出力ペア{k 1、k 2、k 3 →k 2 } を使用できますモデルの重みを更新して、この新しいパターンを学習します。そう次回、履歴シーケンス{k 1、k 2、k 3 }が与えられると、DeepLo​​gは更新された確率でk 1とk 2の両方を出力します。同じアップデート手順は、パラメータ値異常検出モデルに対して機能します。DeepLo​​gを最初から再トレーニングする必要がないことに注意してください。最初のトレーニングプロセスでは、DeepLo​​gのモデルは次のように存在します。一般的な多次元の重みベクトル。e更新プロセスのフィード新しいトレーニングデータ、およびエラーを最小限に抑えるために重みを調整モデル出力とfalseからの実際の観測値の間ポジティブなケース。4ワークフローの構成マルチタスクの実行各ログキーは、ソースコード、VM作成などのタスクはシーケンスを生成しますログエントリの。直感的に、タスクによって生成されたログエントリの順序達成するための各関数の実行順序を表しますこの仕事。結果として、有限状態として作業モデルを構築できます任意のタスクの実行パスをキャプチャするオートマトン（FSA）。ですワークフローモデルは、実行パスの異常を検出するためにも使用できます。ありますが、DeepLo​​gのLSTMモデルに比べて効果が低くなりますタスク間の依存関係と非確定的ループ反復。ただし、作業フローモデルは非常にユーザーが何が問題だったかを診断できるようにするのに役立ちます異常が検出されたときのタスクの実行。の繰り返し実行によって生成されたログシーケンスがタスク、仕事の問題を探るいくつかの作品がありました-OW推論[ 4、 21、42]。CloudSeer [42]は、ワークフローモデルを使用した異常検出のアート。CloudSeerはいくつかの制限。まず、検出できる異常は限られていますログレベルが「ERROR」のエントリをログに記録し、ログエントリをログに記録しない現れる。さらに、モデルの構築に必要な作業には、1つのタスクのみが繰り返し実行されるログファイル。その他の前の作品[ 4ログルから建設OW仕事上、21]この制限にも従う。実際には、ログファイルには複数のタスクによって生成されたログエントリのインターリーブタスク内で同時に実行されているスレッド。4.1複数のタスクからのログエントリの分離簡単なケースは、複数のプログラムが同時に同じログ（Ubuntuのシステムログなど）。各ログエントリにはそれを作成したプログラムの名前。別の簡単なケースはプロセスまたはタスクIDはログエントリに含まれます。ここでは、ユーザープログラムを繰り返し実行して実行する場合そのプログラム内の異なるが、論理的に関連するタスク。重要な注目すべきは、タスクが時間的に重複しないことです。しかし同じログキーが複数のタスクに表示されることがあり、同時実行性各タスク内で可能です（たとえば、1つのタスク内の複数のスレッド）。例として、OpenStack管理ログを検討してください。にとって各VMインスタンス、そのライフサイクルにはVMの作成、VMの停止、VMの削除など。これらのタスクは重複しない、つまりVMが停止する開始できるのは、仮想マシンの作成が完了したときのみです。ただし、同じログキーは、別のタスクで表示される場合があります。たとえば、ログメッセージ「VM再開（ライフサイクルイベント）」は、VMの作成、VMの起動、VMの再開とVMの一時停止の解除。同時に実行されている可能性があります各タスク内のスレッド、順序付けの不確実性につながる1つのタスクに対応するログメッセージの数。たとえば、VMの作成、2つのログメッセージの順序は、「ビルドに*秒かかりましたインスタンス」と「VM再開（ライフサイクルイベント）」は不確かです。私たちの目標は、ログファイル内のさまざまなタスクのログエントリを分離することです。そして、ログに基づいて各タスクの作業モデルを構築しますキーシーケンス。とはいえ、問題の入力はログ全体です生ログファイルから解析されたキーシーケンス、および出力は識別されたタスクごとに1つずつ、作業用モデル。4.2 DeepLo​​gの異常検出モデルの使用4.2.1ログキーの分離。DeepLo​​gのモデルでは、ログキーからの異常検出、入力はログのシーケンスです最近の履歴からの長さhのキー。出力は確率すべての可能なログキー値の分布。興味深い観測その出力は実際に基礎となる作業をエンコードすることです実行パス。直感的に、ログキーシーケンスが与えられると、モデルは何を予測します次に、実行した実行領域に基づいて発生しますトレーニング段階。シーケンスwの後にaが続かない場合トレーニング段階の特定のキー値k、Pr [m t = k | w] = 0。同様に、シーケンスwの後に常にkが続く場合、Pr [m t = k | w] =1。たとえば、シーケンス「25→54」を想定します。出力予測は「{57：1.00}」であり、「25→54→57」は1つのタスクから。より複雑なケースは、シーケンスwが異なるキーのグループからのログキー値が後に続きます。これらのキーが合計して1になる確率。このケースを処理するために、私たちは小さな人から発想を得たアイデアを使用しています不変量マイニング[ 21] 。ログシーケンス「54→57」を考え、予測された確率分布は「{18：0.8、56：0.2}」です。つまり、次のステップは、「18」または「56」のいずれかです。あいまいさができる不十分な履歴シーケンス長を使用することにより発生します。にとってたとえば、2つのタスクが同じ作業フローセグメント「54→57」を共有している場合、最初のタスクには、「18→54→57→18」というパターンがあり、80％実行されますそして、2番目のタスクには「31→54→57→56」というパターンがあります。これは20％の時間実行されます。それはモデルにつながるでしょうシーケンス「54→57」の場合、「{18：0.8、56：0.2}」を予測します。異なるモデルをトレーニングすることでこの問題に対処できます履歴シーケンスの長さ、たとえばこれでh = 2の代わりにh = 3を使用場合。作業の構築中に、ログシーケンスの長さを使用しますこれにより、より確実な予測が可能になります。たとえば、上記の例では、
7ページ
54571825185618561. [25、18、54]-> {57：1.00}2. [18、54、57]-> {18：0.8、56：0.2}3. [54、57、18]-> {56：1.00}[54、57、56]-> {18：1.00}5457182518563131（a）同時実行検出の例5457182524603726日1. [25、18、54]-> {57：1.00}2. [18、54、57]-> {24：0.8、26：0.2}3. [54、57、24]-> {60：1.00}[54、57、26]-> {37：1.00}545718252426日3760（b）新規タスク検出の例26日37394039401. H：[26、37、39]-> {40：1.00}2. H：[37、39、40]-> {39：1.00}3. H：[39、40、39]-> {40：1.00}26日373940（c）ループ識別の例図4：タスクの分離とワークフローの構築にLSTMを使用する例。シーケンス「18→54→57」は、予測{18：1.00}につながり、シーケンス「31→54→57」は、予測{56：1.00}につながります。小さなシーケンスが共有セグメントであることを除外した場合異なるタスクから（つまり、トレーニングのためにシーケンスの長さを増やすそして予測はより確実な予測につながりません）、挑戦lengeは、マルチキー予測出力が同じタスクでの同時実行、または別のタスク。これを分岐点と呼びます。図4a に示すように、発散点が同じタスクの同時実行によって引き起こされる一般的な問題は、予測出力で最も確率が高いキーはお互いに現れ、確実性（より高いもので測定）キーの数が少ない確率）次の予測の場合並行スレッドのいくつかのキーが持っているので、増加しますすでに登場しました。e予測は最終的に確実になります並行スレッドのすべてのキーが履歴に含まれているシーケンス。一方、発散点が図4bに示すように、予測されたログキー候補である新しいタスク（例では「24」と「26」）は互いに表示されません。もしそのような各ログキーを履歴シーケンスに組み込みます。次の予測は、新しいログキーの確定的な予測です（たとえば、「24→60」、「26→37」）。これが事実である場合、私たちは仕事の成長をやめる現在のタスクのモデル（この例ではキー「57」で停止）、および新しいタスクのワークフローモデルの構築を開始します。注意してください図4bの2つの「新しいタスク」は 、「if-else」ブランチにすることもできます。たとえば、「57→if（24→60→…）else（26→37→…）」。そのような状況に対処するために、単純なヒューリスティックを適用します。「新しいタスク」のログキーが非常に少ない場合（例えば、3）そして常に特定のタスクT pに表示される場合、それをT pの「if-else」ブランチの一部。それ以外の場合は新しいタスクとして。4.2.2ワークフローモデルを構築します。ダイバーを区別できたら、同じでの同時実行（複数のスレッド）によって引き起こされるgenceポイントタスクと新しいタスクでは、次のように簡単に作業のモデルを構築できます。図4aおよび図4bに示されています。追加の注意が必要ですループを識別します。eループの検出は実際には非常に簡単です区。ループは常に最初の作業フローモデルでは展開チェーン; 例については、図4cを参照してください。この仕事はチェーンは最初は「26→37→39→40→39→40」ですが、ループ実行としてフラグメントを繰り返した（この例では39→40）。4.3密度ベースのクラスタリングアプローチの使用4.3.1ログキーの分離。別のアプローチは密度を使用することです-ベースのクラスタリング手法。e直感的には、表2：距離d内の共起行列k 1…k j…k nk 1p d（1、1）p d（1、j）…k ip d（i、1）p d（i、j）=fd（ki、kj）d・f（ki）…k np d（n、1）p d（n、j）同じタスクは常に一緒に表示されますが、異なるタスクのキーをログに記録しますタスクの順序が異なるため、常に一緒に表示されるとは限りません異なるタスクの複数の実行中に修正されました。私たちを可能にします共起パターンに基づいてログキーをクラスター化し、共起率が低い場合に異なるタスクへのキー。ログキーシーケンスでは、任意の2つのログキー間の距離はそれらの間のログキーの数+ 1として定義されます。たとえば、シーケンス{k 1、k 2、k 2 }が与えられた場合、d（k 1、k 2）= [1、2]、d（k 2、k 2）= 1（ペア（k 1、k 2）の間に2つの距離値があることに注意してください）。Table 2に示すように共起行列を作成します。要素p d（i、j）は、2つのログキーk iおよびk jの確率を表します入力シーケンスの距離d内に表示されます。具体的には、みましょうf（k i）は入力シーケンスのk iの周波数、f d（k i、k j）距離内で一緒に現れるペア（k i、k j）の頻度入力シーケンスのd。p d（i、j）= fd（ki、kj）d・f（ki）は、k jとk iの重要性。たとえば、d = 1の場合、p 1（i、j）= f1（ki、kj）f（き）= 1 は、k iが出現するたびに、その隣にk jがなければなりません。これで注意してください定義、分母のf（k i）はdによってスケーリングされますが、d内の共起頻度を数えると、キーk iはd回。f（k i）を係数dでスケーリングすると、んj = 1f d（i、j）= 1すべての私のために。複数の共起行列を作成できることに注意してくださいdの距離値が異なる場合。各距離値dの共起行列でビルドが完了したら、目標は一連のタスクTASK =（T 1、T 2、...）を出力することです。クラスタリング手順は次のように機能します。まず、d = 1の場合、anyp 1（i、j）がしきい値τ（たとえばτ= 0.9）より大きいかどうかを確認します。そうです、k i、k jを接続してT 1 = [k i、k j ]を形成します。次に、T 1がその頭部または尾。例えば、Kが存在する場合、X ∈KようにP 1（K I、K X）>τは、さらに、p 2（k j、k x）>τかどうか、つまりk jとk xが大きいかどうかをチェックします距離内の共起確率2.ある場合、T 1 = [k x、k i、k j ]、そうでなければ、T 2 = [k i、k x ]をTASKに追加します。TASKのタスクTが処理できなくなるまで手順が続行されますか？それから拡張されました。タスクTが拡張される一般的な場合
8ページ
k xを含めることができるかどうかを確認するときに、2つを超えるログキーがある新しいヘッドまたはテールとして、k xが共起しているかどうかを確認する必要があります距離dまでのTの各ログキーでτより大きい確率ここで、dは次のうち小さい方です：i）Tの長さ、ii）最大値の共起行列を作成したdの。例えば、T = [k 1、k 2、k 3 ]がk 4をその末尾で接続する必要があるかどうかを確認するには、min（p 1（k 3、k 4）、p 2（k 2、k 4）、p 3（k 1、k 4））>τ かどうかを確認します。上記のプロセスは、各タスクの順次ログキーを接続します。タスクT 1 = [k i、k j ]を拡張して任意のsin-キーを1つ、T 1を2つのログキーで拡張できるかどうか、つまりk x、k∈K が存在し、p 1（k i、k x）+ p 1（k i、k）>τ、またはp 1（k j、k x）+ p 1（k j、k）>τ。次のケースがtrueであるとします。確認することは、k xとkがcon-タスクT 1の現在のスレッド。もしそうなら、p d（k j、k x）は常に増加しますより大きなd値、つまり、p 2（k j、k x）> p 1（k j、k x）で、直感的並行スレッドからのキーの出現順序のため確かではありません。そうでなければ、k xとkはT 1に属さないので、代わりにT 2 = [k j、k x ]およびT 3 = [k j、k]をTASKに追加します。最後に、TASKの各タスクTについて、そのシーケンスが別のタスクのサブシーケンスとして含まれています。4.3.2ワークフローモデルを構築します。ログキーシーケンスが9つになったら、各タスクで評価され、識別されたワークフローモデルモデルタスクの構造は、セクション4 .2.2と同じ説明に従います。4.4ワークフローモデルの使用4.4.1 DeepLo​​gモデルのパラメーターを設定します。セクション3.1では、特に、DeepLo​​gには複数の入力パラメータが必要であることを示しています。lar、履歴シーケンスウィンドウhの長さが必要です（トレーニング用と検出）、および予測された正常と見なされる確率分布関数を出力します。hに適切な値を設定することは問題に依存します。Gen-一般的に言えば、h値が大きいほど予測精度が向上します。LSTMではより多くの履歴情報が利用されるため、歴史の中ではるかに古いキーが出現するキーの予測に貢献します。この時点で続きますhを増やしても、LSTMの予測精度は損なわれません。LSTMは長い間最近の歴史だけを知ることができるのでしたがって、シーケンスマーはロングテールを無視します。ただし、大きな値パフォーマンスに影響があります。より多くの計算（およびレイヤー）トレーニングと予測の両方に必要であり、速度が低下するDeepLo​​gのパフォーマンス。一方、の値は、真のポジティブの間のトレードオフを調整します（異常検出率）および誤検知（誤警報率）。eワークフローモデルは、適切な値を設定するためのガイダンスを提供しますhと。直感的に、hは、適切な予測を行うために必要な依存関係を組み込む、したがって、hを最短の作業時間の長さに設定できます。e番号可能な実行パスのは、の適切な値を表します。したがって、すべての分岐点での分岐の最大数として設定すべてのタスクの仕事から。4.4.2ワークフローを使用して検出された異常を診断する。いつでもDeepLo​​gによって異常が検出された場合、ワークフローモデルはこの異常を診断し、その方法と理由を理解するために使用されますそれが起こった。図5に例を示します。履歴を使用するシーケンス[26、37、38]、DeepLo​​gからの上位予測はログキーです39（= 1）、ただし、実際に表示されるログキーは67です。これは異常です。この作業モデルの助けを借りて26日373839404167実際の実行予測（正しいパス）37：インスタンス：*インスタンスの終了38：インスタンス：*インスタンスは正常に破棄されました39：インスタンス：*インスタンスファイルの削除*40：インスタンス：*の削除*完了41：インスタンス：*ハイパーバイザー上のインスタンスを破棄するために*秒かかりました67：インスタンス：*フィルター解除中のlibvirtからのエラー。コード= *エラー= *図5：ワークフローを使用した異常診断。タスク、ユーザーは簡単に現在の実行ポイントを特定できます対応する作業の流れ、さらにこのエラーが「インスタンスが正常に破棄されました」以前に発生した「インスタンスファイル*を削除しています」。これは、このエラーが発生したことを意味しますクリーンアップ中にVMが破壊された。4.5ディスカッション[前の作品4、 21、42]から作業OWSの構築に焦点を当て1つのタスクの複数の実行。彼らのアプローチの基本的な考え方3つのステップに従います。1）ログの各ペアの一時的な依存関係をマイニングします。キー; 2）ペアワイズ不変量から基本的な作業を構築するステップ1で識別されます。3）入力ログキーを使用したワークフローモデルシーケンス。主な制限は、彼らがで動作することができないことです複数のタスクまたは並行スレッドを含むログシーケンス私たちの研究によって対処される1つのタスクで。私たちのタスクの分離方法論は、仕事の流れに向けた有用な洞察も提供します各タスクの構築。5評価DeepLo​​gはKeras [6 ]とTensorFlow [2] を使用して実装されますバックエンド。このセクションでは、各コンポーネントの評価を示しますDeepLo​​gの全体的なパフォーマンス。その有効性を示します。大規模なシステムログデータから異常を見つけること。5.1実行パス異常検出このセクションは、ログキーの異常検出の評価に焦点を当てていますDeepLo​​gのモデル。まず、その効果を大規模に比較します以前の方法でシステムログを作成し、影響を調査するDeepLo​​gの異なるパラメータのセット。5.1.1以前の方法。汎用ログに関する以前の作業異常検出は同様の手順に従います。最初に異常を検出します各ログメッセージからキーを記録し、異常検出を実行するログキーシーケンス。e主成分分析（PCA）メソッド[39 ]は簡単にできるログファイルに異なる「セッション」があること各ログエントリに追加されたセッションIDで識別されます。最初のグループセッションごとにキーを記録し、出現回数をカウントします各セッション内の各ログキー値の。セッションベクトルは各ログキーの出現回数を表すサイズnそのセッションでKで。各列が次の場所にあるマトリックスが形成されますログキー。各行は1つのセッションベクトルです。PCAは投影の長さを測定することによる異常なベクトル（セッション）変換された座標系の残余部分空間 ですアプローチは、そのオンライン対応よりも効果的であることが示されています
9ページ
オンラインPCA [38 ]特に誤検知の削減において、これは明らかにオフラインの方法であり、オンライン異常には使用できません検出。e実装は[ 17]によってオープンソース化されています。インバリアントマイニング（IM）[22 ]は、PCAと同じ行列を作成しますアプローチはします。IMは、満足できる可能性のある小さな不変条件を最初にマイニングしますベクトルの大多数によって、それからそれらのベクトルを扱います異常な実行セッションとしてこれらの不変条件を満たさない。ですアプローチは以前の研究よりも効果的であることが示されている[ 11 ]これはオートマトンを使用しています。e実装はオープンです[ 17]によって供給。TFIDFは[ 44]で開発されました。その目的はITシステムですが故障検出とは異なり、異常検出とは異なります。[39 ]に示す。それにもかかわらず、このメソッドをLSTMベースのアプローチも使用するため、評価。いくつかあります主な違い。TFIDFは、時間枠ごとにログキーをグループ化します（毎回ウィンドウはユーザーパラメータによって定義されます）、その後毎回モデル化しますTF-IDF（項頻度、逆数）を使用したウィンドウ（「エポック」と呼ばれる）ドキュメントの頻度）ベクトル。eラプラス平滑化手順使用には、エポックの総数の知識が必要です（したがって、ログファイル全体）。TFIDFはLSTMモデルをバイナリとして構築します分類された正常なデータと異常なデータの両方が必要ですトレーニング。異常なログエントリを取得するだけでなく、トレーニングデータに含まれていない新しいタイプの異常は、検出されません。対照的に、DeepLo​​gはLSTMモデルをマルチクラスの分類子であり、トレーニングには通常のデータのみが必要です。CloudSeerは、マルチユーザー向けに特別に設計されたメソッドです。スタックログ[42 ]。各OpenStack VMの作業モデルを構築します。関連タスクであり、異常検出のための作業フローを使用します。あれOpenStackログで許容可能なパフォーマンスを実現します（精度は83.08％、および論文で報告されているとおり90.00％の再現率）、この方法他のタイプのログ（HDFSログなど）では機能しません。ログキーの範囲ははるかに不規則です。たとえば、Cloud-Seerのみが「同じ回数表示される」ログキーモデルすべてのセッションで。HDFSログでは、29のログキーのうち3つのみが満足しますこの基準。さらに、この方法ではログエントリを分離できません1つのログ内の異なるタスクを別々のシーケンスに。に依存していますこれを達成するための複数の識別子汎用ログ。ここでは比較されません。5.1.2ログデータセットとセットアップ。HDFSログデータセット。Hadoopベースの実行によって生成されます200を超えるAmazonのEC2ノードでのmap-reduceジョブ、およびHadoopドメインの専門家に導かれました。11、197、954ログエントリ収集されているが、約2.9％は異常であり、「書き込み例外」として。によって最初に使用されたメインデータセットでしたo ine PCAベースの[39 ]メソッドで、その後、いくつかのオンラインPCA [ 38 ]およびIMベースの[22]メソッドを含むその他の作業。このデータセットの詳細は、[ 38、39 ]に記載されています。OpenStackログデータセット。OpenStack実験をデプロイしました（バージョンMitaka）1つのコントロールノード、1つのネットを備えたCloudLab [ 30]作業ノードと8つの計算ノード。1、335、318のログエントリ収集され、約7％が異常です。スクリプトを実行してVMの作成/削除など、VM関連のタスクを即座に実行します。停止/開始、一時停止/一時停止解除、および一時停止/再開。VMタスクは正規表現の範囲でスケジュールされている（作成（ストップスタート）{0,3}（一時停止の一時停止）{0,3}（一時停止の再開）{0,3}削除）+ 。VMライフサイクルは「VM作成」で始まり、「VM削除」で終わりますが、タスク「Stop-Start」、「Pause-Unpause」、「Suspend-Resume」などのペアライフサイクル内で0〜3回ランダムに出現する可能性があります。INFOnova-api、nova-scheduler、nova-computeのレベルログはElastic Stack [33 ] を使用して分析のために収集および転送されます。リ異なる種類の異常が異なる実行ポイントに注入されました：1）VM作成中の中性子タイムアウト。2）destroy-中のlibvirtエラーVMを使用します。3）クリーンアップ中にlibvirtエラーが発生し、VMが破壊されます。セットアップ。PCAベースおよびIMベースのメソッドを実行するために、識別フィールドによって異なるセッションにエントリを記録します。HDFSログはblock_idで、OpenStackのログはinstance_idです。各セッショングループは、1つのブロックのライフサイクルまたはVMインスタンスの再指定です。あれこれ。次に、各ログエントリを解析してログキーにします。DeepLo​​gは重みをトレーニングするためにログキーに直接適用し、その後異常の検出に使用できますが、他の方法ではもう1つ必要ですステップ。それぞれの外観の出現回数を数える必要があります各セッション内でtinctログキーを作成し、それぞれが列は個別のログキー（n列になるため）であり、それぞれ行は、セッションベクトルを表し、そして細胞のVの値IJで行列は、i番目のセッションのログキー k jの数を表します。DeepLo​​gのトレーニングには、通常のログエントリのごく一部が必要です。モデル。HDFSログの場合、通常のセッションの1％未満（最初の100,000ログエントリから解析された4,855セッションが比較されました合計11,197,954）がトレーニングに使用されます。なお、DeepLo​​g（対応するログキーとともに）ログエントリを特定できます異常ですが、同じメジャーを使用して比較するために競合する方法では、異常の粒度として「セッション」を使用します検出、つまり、sessionCは、異常なセッションと見なされます。異常が検出されたCからのログキーが少なくとも1つ存在するため。表3は、2つのデータセットをまとめたものです。PCAとIMトレーニングデータを必要としない監視対象外の方法であり、一方、DeepLo​​gには通常のトレーニングデータのみが必要ですシステム実行、およびTFIDFには正常と異常の両方が必要トレーニングするデータ。ログセッション数n：番号データセットトレーニングデータ（必要な場合）テストデータログキーのHDFS4,855ノーマル。553,366正常;29日異常1,63815,200異常OpenStack 831は正常です。5,990ノーマル。4050異常453異常表3：ログデータセットのセットアップ（単位：セッション）。偽陽性（FP）と偽陰性の数に加えて、動機（FN）、Precision、Recallなどの標準的な指標も使用しますとFメジャー。精度= TPTP + FP （TPは真陽性の略）ショー検出されたすべての異常の中の真の異常の割合。リコール= TPTP + FN は、データの異常の割合を測定します設定されている（グラウンドトゥルースを知っていると想定）。そしてF-measure = 2・Precision・RecallPrecision + Recallは、2つの調和平均です。デフォルトでは、DeepLo​​gには次のパラメーター値を使用します。= 9、h = 10、L = 2、α= 64、それらの影響を調査私たちの実験では。リコールは予測でカットを決定します通常と見なされる出力（つまり、次に出現する確率は正常と見なされます）、hはトレーニングと検出に使用されるウィンドウサイズ。Lとαは、DeepLo​​gのレイヤー数とメモリユニット数それぞれ1つのLSTMブロック。他のすべての方法については、
10ページ
PCAIMTFIDFNグラムDeepLo​​g誤検知（FP）2772122958331360833偽陰性（FN）54001217年1256739619表4：HDFSログのFPとFNの数。それらのパラメータ空間とそれらの最高の結果を報告します。N-グラム法が使用され、特に指定されない限り、N = 1に設定します。これは、N-gramメソッドの最高のパフォーマンスを示しています。5.1.3比較。表4 は誤検知の数を示していますHDFSデータの各メソッドの偽陰性。PCAが達成する最も少ない偽陽性ですが、より多くの偽陰性を犠牲にしています。図6aは、再現率と精度を使用したより詳細な比較を示していますとFメジャー。TFIDFはこの図から省略されていることに注意してください。限られたスペースとその非常に貧弱な相対的なパフォーマンスの。明らかに、DeepLo​​gは、全体的に最高のパフォーマンスを実現しています。Fメジャーは96％。私たちのベースラインソリューションであるN-gramも、履歴の長さが1の場合に良好なパフォーマンス。ただし、そのパフォーマンス履歴ウィンドウが長くなると劇的に低下します。対照的に、セクション5 .1.4に示すように、LSTMベースのアプローチはより安定しています。図6bは、DeepLo​​gが使用するトップアプローチを調査しています予測アルゴリズム。D tをトップログのキー値のセットとするDeepLo​​gによってtで予測され、m tは実際のログキー値ですtのデータに表示されます。この戦略の影響を確認するために、PrのCDF研究[MをT ∈D T ]ジerent値について。の中で予測する11,000,000のログキー（通常のラベルが付けられている）、88.9％DeepLo​​gの上位予測のうち、m tと正確に一致します。及び96.1％で、m個のTさんDeepLo​​gの上位2つの予測の範囲内です。いつ= 5、99.8％通常のm tはD t内にあり、その間、異常検出率99.994％です（1つの異常セッションのみが検出されませんでした）。図7aは、OpenStackデータセットのパフォーマンスを示しています。ePCAアプローチは、このデータセットで妥当なパフォーマンスを示していますが、低い精度（77％のみ）で、IMが達成したにもかかわらずこの場合の完全な再現率、精度は2％と非常に低い（ほとんどすべてのVMインスタンスが異常な実行として検出されます）。これは、OpenStackログが次のようにランダムに生成されたためですセクション5.1で説明します。2.そのキーをログに記録する回数（Stop Start）などは、VMのライフサイクルに表示される場合があります（作成と削除のペア）は不確かです。それは本当に難しいです異常検出のための「安定した小さな不変条件」を見つけるIM。この仮説をテストするために、2番目のデータセットを生成しました（Create Delete）+のような確定的パターンで、合計は5,544の通常のVM実行と170の異常なVM実行。表すこのデータセットをOpenStack IIとして設定し、結果を図7bに示します。IMは、このデータセットで非常によく機能し、より定期的なパターンを使用します。ただし、PCAメソッドの再現率は、この場合2％にしか低下しません。データの通常のパターンが規則的すぎるため、レンダリング分散が機能しないことにより異常を検出するPCAメソッド。一方、DeepLo​​gは優れたパフォーマンスを発揮します両方のOpenStackログで、Fメジャーが98％および97％のrespec-あれこれ。最後に、PCAとIMはオフラインであることに注意することも重要です。メソッド、および異常検出を実行するために使用することはできませんログエントリごと。異常はセッションレベルでのみ検出できます。しかし、セッションの概念は、多くのシステムログには存在しない場合もあります。5.1.4 DeepLo​​gの分析。私達は性能のim-を調査しますDeepLo​​gのさまざまなパラメータの協定：、h、L、およびα。e結果を図8に示します。各実験では、他のパラメータのデフォルト値を使用しながら、1つのパラメータの値。精度想起Fメジャー（a）HDFSの精度。0.50.60.70.80.91.01.10.980.670.790.880.950.910.920.960.940.950.960.96PCAIMNグラムDeepLo​​gg = 1g = 3g = 5g = 7g = 9g = 11（b）上位g予測の累積確率。0.860.880.900.920.940.960.981.000.8890.9610.9810.9930.9980.99940.9998図6：HDFSログの評価。精度想起Fメジャー（a）OpenStack Iでの精度。0.00.20.40.60.81.00.770.990.870.021.00.050.911.00.950.961.00.98精度想起Fメジャー（b）OpenStack IIの精度。0.00.20.40.60.81.0 1.00.020.030.831.00.910.831.00.910.940.990.97PCAIMNグラムDeepLo​​g図7：OpenStackログの評価。一般的に、DeepLo​​gのパフォーマンスは、異なる値に、すなわちそれはの調整に非常に敏感ではありませんこれらのパラメーター値のいずれか1つまたは組み合わせ。作りますDeepLo​​gの導入と実際の使用は簡単です。e結果はかなり直感的に理解することもできます。たとえば、図8cは、値が大きいほど、精度は高くなりますが再現率は低くなります。我ら、より高い真陽性率またはより低い値を達成するように調整できます偽陽性率。最後に、DeepLo​​gのログエントリあたりの予測コスト標準のワークステーションでは約1ミリ秒です。GPUを使用するなどのハードウェアによってさらに改善することができます。12３45（a）レイヤー数：L0.50.60.70.80.91.03264128192256（b）メモリユニット数：®。0.50.60.70.80.91.0g = 7g = 8g = 9g = 10g = 11g = 12（c）通常の上位g予測。0.50.60.70.80.91.05678910（d）ウィンドウサイズ：h。0.50.60.70.80.91.0精度想起Fメジャー図8：異なるパラメーターを使用したDeepLo​​gのパフォーマンス。5.2パラメータ値とパフォーマンスの異常検出パラメータでのDeepLo​​gの有効性を評価するには値とパフォーマンス（ログエントリ間の経過時間を含む）
11ページ
異常、OpenStack VM作成のシステムログを使用仕事。データセットには両方のタイプの異常が含まれています：パフォーマンス異常（ログエントリの遅い到着）およびパラメーター値の異常（VM作成時間が他よりもはるかに長いログエントリ）。実験設定。以前と同様に、OpenStackエキスパートをデプロイしました。CloudLabでimentし、その複数をシミュレートするスクリプトを書いたユーザーは常にVMの作成と削除を要求しています。中OpenStack VMの作成、重要な手順は、コントローラーノードから計算ノードに必要なイメージ（ここでVMが作成されます）。パフォーマンスの異常をシミュレートするにはDoS攻撃によって引き起こされる可能性があります。ネットワークをスローしますコントローラーから2つの異なるポイントでノードを計算する速度これらの異常がDeepLo​​gによって検出できるかどうかを確認します。異常検出。セクション3.2で説明したように、ログを分離します2セットへのエントリ。1セットはモデルトレーニング用で、もう1セットはモデルトレーニング用です。セット（検証セットと呼ばれます）は、モデルを適用してMSEのガウス分布（平均二乗誤差）。その後すべての入力パラメーター値ベクトルのオンライン検出フェーズ−→、DeepLo​​gは−→と予測の間のMSEがモデルからの出力（ベクトルも）は許容範囲内ですからのMSEのガウス分布の信頼区間検証セット。図9は、パラメーター値の検出結果を示しています異なるログキーのベクトル。ここで、x軸は、作成されるVM（つまり、異なるVM作成インスタンス）、および-axisパラメータ値ベクトルとDeepLo​​gからの予測出力ベクトル。それぞれの水平線gureは、対応する圧縮間隔のしきい値です。MSEガウス分布。図9aと9bは2つのログキーを表しますそれらのパラメータ値ベクトルは全体を通して正常です時間。図9cと9dは、パラメーター値ベクトルがキー53と56は、異常なものとして正常に検出されました私たちがネットワークを主導した2つの瞬間速度（つまり、注入された異常）。検出された異常なパラメータ値ベクトルごとに、予測に最も影響する値を特定し、異常な列（機能）。私たちは2つが異常であることがわかりましたキー53の不正なパラメータ値ベクトルは異常に大きいためです経過時間の値。一方、キー56は「Took * seconds toインスタンスをビルドします。」と、当然のことながら、その2つの異常なパラメータ値ベクトルは、異常に大きい値（秒）が原因で発生しました。5.3 DeepLo​​gのオンライン更新とトレーニングセクション5.1は、DeepLo​​gには非常に小さいトレーニングセット（ログ全体の1％未満）を必要としないトレーニング段階でのユーザーフィードバック。しかし、検出段階で新しいシステム実行パスが表示されることがあるこれも正常ですが、異常ではなかったため、異常として検出されましたトレーニングデータに反映されます。この問題に対処するために、このセクションDeepLo​​gのオンライン更新とトレーニングの有効性を評価しますセクション3.3で説明されているモジュール。これを使用して増分の有無による検出結果の違い有効性と効率の両方の観点から、更新。5.3.1ログデータセット。このセクションで使用されるログデータセットは青ですGene / Lスーパーコンピューターシステムログ1、4,747,963ログを含む1 CFDRデータ、h ps：//www.usenix.org/cfdr-data050100150200250300VM ID（a）ログキー25の値ベクトル0.00.51.01.52.0MSECI = 99％CI = 99.9％CI = 98％050100150200250300VM ID（b）ログキー45の値ベクトル0.00.51.01.5MSECI = 99％CI = 99.9％CI = 98％050100150200250300VM ID（c）ログキー53の値ベクトル012３456MSECI = 99％CI = 99.9％CI = 98％050100150200250300VM ID（d）ログキー56の値ベクトル012３456MSECI = 99％CI = 99.9％CI = 98％図9：dif-を使用したパラメーター値ベクトルの異常検出正確なコンデンス間隔（CI）。そのうち、348,460エントリは異常としてラベル付けされています。選びました重要な特性のため、このデータセット：多くのログキー特定の期間にのみ出現した。であるということはトレーニングデータセットには、考えられるすべての通常のログキーが含まれていない場合があります。単独ですべての可能な通常の実行パターン。5.3.2評価結果。2つの実験を行いました。最初の1％の通常のログエントリをトレーニングデータとして使用し、その他の最初の10％のログエントリをトレーニングに使用します。どちらの場合も、残りの99％または90％のエントリは異常検出に使用されます。我々L = 1、α= 256、= 6、h = 3に設定します。0.00.20.40.60.81.00.161.000.270.821.000.900.00.20.40.60.81.00.161.000.280.881.000.93オンライントレーニングなしオンライントレーニングあり図10：Blue Gene / Lログの評価。図10は、オンライントレーニングの有無による結果を示しています両方の実験で。「オンライントレーニングなし」の場合、DeepLo​​gを実行して、増分なしで受信ログエントリをテストする更新。「オンライントレーニングあり」の場合は、検出された異常が偽であるかどうかを報告するエンドユーザーがいるポジティブ。その場合、DeepLo​​gはそのサンプル（現在はラベル付きレコード）を使用しますモデルを更新して、この新しい分野を学習します。図10はオンライントレーニングがなく、1％のトレーニングデータしかありません。これにより、多くの誤検知が発生します（したがって、精度が非常に低くなります）。トレーニングデータを10％に増やしても、精度、そのパフォーマンスはまだ不十分です。一方、オンライントレーニングを備えたDeepLo​​gは、Precisionを大幅に改善します。したがって、Fメジャースコア。真陽性率100％（完璧な想起）両方の分野で、オンライントレーニングは誤検知を減らします
12ページ
1％のトレーニングデータで40.1％から1.7％、38.2％から1.1％の割合それぞれ10％のトレーニングデータ。表5は、各ログエントリを確認するための償却コストを示しています。にとってオンライントレーニングの場合、両方の検出にかかる時間を報告しましたオンライン更新（更新がトリガーされた場合）。結果は、オンライン更新とトレーニングにより、ログあたりの償却コストが増加するエントリが、少しだけ。これは、多くのログエントリが更新をトリガーします。オンライン更新とオンライン検出では、並行して実行されます。モデルが更新されている間に更新が実行されます現在の重みを使用して検出を続行します。表5：各ログエントリを確認するための償却コストトレーニングデータの割合1％10％オンライントレーニングなし（ミリ秒）1.06 1.11オンライントレーニングあり（ミリ秒）3.48 2.465.4セキュリティログのケーススタディ通常のログには表示されなかったログキーを持つ異常トレーニングに使用される（たとえば、「エラー」または「例外」ログメッセージ）検出しやすい。DeepLo​​gは、はるかに微妙なものを効果的に検出できますケース。たとえば、HDFSログでは、「Namenode not update a er「ブロックを削除」の異常は、セッションでログキーが見つからないこととして示されます。また、「冗長なaddStoredBlock」異常が追加のログとして表示されるキー。の変更を引き起こす可能性のある任意のackのことですシステムの動作（ログで反映）として検出できます。に次に、実際の確認を含むシステムログを調査します。DeepLo​​gの有効性を示します。5.4.1ネットワークセキュリティログ。ネットワークセキュリティは非常に重要ですトランス。壁と侵入検知システム（IDS）の両方が生成オンライン異常検出に使用できるログ。ネットワークセキュリティログでのDeepLo​​gのパフォーマンスをテストするために、VASTチャレンジ2011データセット、具体的にはミニチャレンジを使用2 —コンピュータネットワーク操作[1 ]。挑戦はすることです視覚化手法を使用して、疑わしいアクティビティを手動で探します。それは異常な活動のためのグラウンドトゥルースが付属しています。すべての異常テーブルトゥルースにあるテーブル図6は、DeepLo​​gの結果を示しています。e検出されていない不審なアクティビティのみが最初に表示されます文書化されていないコンピュータのIPアドレス。表6：VASTチャレンジ2011のネットワークセキュリティログの検出ション不審な活動検出された？1日目：サービス拒否攻撃はい、キーの異常をIDSログに記録します1日目：ポートスキャンはい、キーの異常をIDSログに記録します2日目：ポートスキャン1はい、キーの異常をIDSログに記録します2日目：ポートスキャン2はい、キーの異常をIDSログに記録します2日目：ACKをソーシャルエンジニアリングはい、壁のログにキーの異常を記録します3日目：文書化されていないIPアドレス番号e DeepLo​​gが報告したときに発生したのは誤検知のみのケース短期間に何度も繰り返し表示されるログメッセージ異常として。突然破裂した出来事によるものです同じログメッセージを短時間で何度も出力しました。VASTチャレンジでは、不審なアクティビティとして識別されていません。5.4.2 BROP ACK検出。ブラインドリターン指向プログラム-ming（BROP）aack [5 ]は、多くのサーバーアプリケーションがサービスは、サービスの信頼性を確保するためにクラッシュを再起動します。は優しいですackのどちらも強力で実用的ですソースコードやバイナリへのアクセスに依存しています。スタックバッファサーバーをクラッシュさせる脆弱性は、実行するのに十分ですこれはおかしい。BROPエクスプロイトでは、攻撃者はサーバークラッシュをROPの完了を支援する信号シェルコード。ただし、サーバーの再起動アクティビティが繰り返されると、以下に示すように、カーネルログ内の多くの非定型ログメッセージDeepLo​​gによって簡単に検出されます。nginx [*]：nginx [*]の* ip * sp *エラー*でのsegfaultnginx [*]：nginx [*]の* ip * sp *エラー*でのsegfaultnginx [*]：nginx [*]の* ip * sp *エラー*でのsegfault……5.5タスクの分離とワークフローの構築セクション4で提案された方法を実装し、評価したさまざまなOpenStack VM関連タスクのログ。両方のLSTMアプローチと密度ベースのクラスタリングアプローチは、すべてのタスクを分離します。最初の方法ではLSTMが必要です。監視付きですトレーニングデータを提供する必要がある方法。e秒メソッドは、特定の範囲内のログキーの共起でクラスタリングを使用します監視されていない方法である距離のしきい値。したがって、トレーニングは必要ありませんが、パラメータτは距離のしきい値。具体的には、密度ベースのクラスタリングアプローチの場合、科学的に大きなしきい値τ∈[0.85、0.95]、明確なすべてのタスクの分離。τの値は大きすぎてはいけないことに注意してください（例えば、τ= 1を設定）、バックグラウンドプロセスはログエン同じ場所からログエントリを破壊するランダムな場所で試行します別のタスク。次に、VM作成作業の一部を使用して、その方法を示します。セクション5.2でパフォーマンス異常の有用な診断を提供します。セクション5の 2を思い出してください。パラメーター値のベクトル異常が特定されていますログキー53の経過時間の値、およびパラメータログキー56の位置（ビルドする秒数を表します）インスタンス）。図11に示すように、異常が検出されるとDeepLo​​g、そのインスタンスの構築にかかる時間が異常であることを知っています。理由はわかりません。en、ログ間の経過時間キー53と以前のログキーが大きすぎます。DeepLo​​gによって構築された作業モデル。以前のキーは52です。「イメージの作成」により、VMの作成に時間がかかったことがわかります画像を作成する時間が長すぎるため、通常よりも長くなります。さらにこの手順に続く調査はそれが引き起こされたことを明らかにするかもしれません制御ノードから計算ノードへのネットワーク速度が遅い。6関連研究主にデバッグを容易にするために注目すべきイベントを記録するために設計され、システムイベントログは情報が豊富で、実際に存在しますすべてのコンピュータシステムで、それらをシステムステータスの追跡と調査。ただし、システムログは多様な自由形式のテキストで主に構成されているため、分析は困難です。多数のログマイニングツールがさまざまなシステム用に設計されています。tems。多くの使用ルールベースのアプローチ[7、15、28、29、31、32、40、41]、正確ではありますが、特定のアプリケーションシナリオに限定されます。iOSおよびドメインの専門知識も必要です。たとえば、Beehive [ 41 ]
13ページ
44235253322551185457561844：インスタンス：*主張を試みています：メモリ*ディスク* vcpus * CPU51：インスタンス：*成功したクレーム23：インスタンス：* GET * HTTP \ /1.1 "ステータス：* len：*時間：*52：インスタンス：*画像の作成53：インスタンス：* VMが開始しました（ライフサイクルイベント）32：インスタンス：* VM一時停止（ライフサイクルイベント）18：インスタンス：* VM再開（ライフサイクルイベント）……56：インスタンス：*インスタンスの作成に*秒かかりました図11：OpenStack VMの作成作業。監視されていないクラスによるログから潜在的なセキュリティ脅威を特定しますデータ固有の機能を繰り返し、手動で外れ値にラベルを付けます。Oprea [ 28]は、信念伝播を使用して初期段階の企業を検出しますDNSログからの感染。PerfAugur [32 ]は特に設計されています特別な方法でサービスログをマイニングすることによるパフォーマンスの問題述語の組み合わせなどの機能をカスタマイズしました。DeepLo​​gは一般的ですドメイン固有の知識に依存しないアプローチ。異常の検出にシステムログを使用するその他の一般的な方法通常、2ステップの手順を適用します。まず、ログパーサ[ 9、 14、16、 23、36、37]はその構造の形に解析ログエントリに使用されています通常、「ログキー」（または「メッセージタイプ」）のみが含まれます。パラメータ値とタイムスタンプは、以下の識別子を除いて破棄されますログエントリを分離およびグループ化するために使用されます。en、異常検出ログキーシーケンスに対して実行されます。典型的な方法は生成することですカウントすることにより、各セッションまたは時間枠の数値ベクトル一意のログキー、またはTF-IDFなどのより高度なアプローチを使用します。これらのベクトルで構成されるマトリックスは、マトリックスに適していますプリンシパルなどの監視なしの異常検出方法に基づく成分分析（PCA）[38 、39 ]および不変マイニング（IM）[22]。このようなマトリックスの作成は、簡単なプロセスであり、メソッドはログエントリレベルの異常検出を提供できません（むしろ、セッションレベルでのみ動作します）。読者を紹介します[17これらの方法の概要と比較するため]。教師付き方法[17 、 44]に正常および異常なベクターを使用します将来の異常を検出するバイナリクラシファイアをトレーニングします。の欠点そのような方法は、訓練データにない未知の異常が検出されません。さらに、異常なデータを取得することは困難ですトレーニングのため。評価で示したのは、トレーニングする通常のデータのごく一部で、DeepLo​​gはオンラインで実行できますより優れたパフォーマンスの異常検出。さらに、DeepLo​​g異常検出にタイムスタンプとパラメータ値も使用します前作にはないものです。作業構造は主にログキーを使用して研究されています[4 INEログレOから抽出された、 11、21、42]。示されていますこれにより、異常検出の利点が限定されます[ 11、42 ]。代わりに、仕事の主な用途は、システム診断を支援することです。sis [ 4、21 ]。ただし、過去のすべての作業は、モデルのみのログファイルを想定しています。1つの単一タスクの繰り返し実行が含まれます。この論文では、異なるタスクをログから自動的に分離する方法を提案する異なるタスクの作業モデルを構築するためのファイル。仕事のほかに、異常診断を実行する他のシステムシステムログを使用するnosisには、診断するDISTALYZER [ 26]が含まれます問題のあるログとの比較によるシステムパフォーマンスの問題履歴をクラスタリングして整理する通常のLogCluster [ 19]CALヘルプ将来の問題同定カチオンにログインし、スティッチ[ 45]そのシステムログとビルドから異なるレベルの識別子を抽出しますユーザーがそれぞれの進行状況を視覚的に監視するためのWebインターフェースセッションとパフォーマンスの問題を見つけます。それらは異常が検出された後の診断目的異常検出自体に使用されます。7結論紙は、DeepLo​​gの汎用フレームワークです。ディープニューラルを使用したオンラインログ異常の検出と診断ネットワークベースのアプローチ。DeepLo​​gはログ全体を学習してエンコードしますタイムスタンプ、ログキー、パラメータ値を含むメッセージ。それ異常検出を、ログエントリレベルではなく、ログエントリレベルで実行します以前の多くの方法が制限されているセッションレベルごと。DeepLo​​gさまざまなタスクをログファイルから分離して、作業を構築できますディープラーニング（LSTM）と古典的なマイニング（密度クラスタリング）アプローチ。が有効になります能動的異常診断。ユーザーのフィードバックを組み込むことにより、DeepLo​​gLSTMモデルへのオンライン更新/トレーニングをサポートしているため、新しい実行パターンを組み込んで適応する。広範な評価大きなシステムログでの評価により、以前の方法と比較したDeepLo​​gの有効性。将来の作業には、他の組み込みが含まれますが、これらに限定されませんテストするDeepLo​​gへのRNN（リカレントニューラルネットワーク）のタイプそれらの効率、および異なるアプリケーションからのログデータの統合およびより包括的なシステム診断を実行するためのシステム（例、MySQLデータベースの障害は、ディスク障害が原因である可能性があります。別のシステムログに反映されます）。8謝辞e作者は、匿名の査読者。著者はNSF助成金からのサポートに感謝します1314945および1514520。FeifeiLiも一部NSFCでサポートされています61729202を付与します。TCloudのすべてのメンバーに感謝します有益な議論とフィードバックのためのプロジェクトとフラックスグループ、特にCai（Richard）Li氏は、BROPについての貴重な情報を提供してくれました。参考文献[1] VASTチャレンジ2011。2011。MC2-コンピュータネットワーキングオペレーション。（2011）。hp：//hcil2.cs.umd.edu/newvarepository/VAST%20Challenge%202011/challenge / MC2％20-％20Computer％20Networking％20Operations / [オンライン; 交流-2017年5月8日終了]。[2]MartınAbadi、Paul Barham、Jianmin Chen、Zhifeng Chen、Andy Davis、Je reyDean、Ma hieu Devin、Sanjay Ghemawat、Geo rey Irving、Michael Isard、その他。2016. TensorFlow：大規模な機械学習のためのシステム。手続き中オペレーティングシステムの設計と実装に関するUSENIXシンポジウム（OSDI）。264–285。[3]ヨシュアベンジオ、レジャンドゥカルム、パスカルヴィンセント、およびクリスチャンジョヴァン。2003. A神経確率言語モデル。機械学習ジャーナル2月3日（2003）、1137–1155。[4] Ivan Beschastnikh、Yuriy Brun、Michael D Ernst、およびArvind Krishnamurthy。2014.同時実行システムのモデルをそれらの動作のログから推測するCSight。手続き中 ソフトウェア工学に関する国際会議（ICSE）。468〜479。[5]アンドレア・ビ・アウ、アダム・ビレイ、アリ・マシザデ、デビッド・マジエレス、ダン・ボネ。2014.ハッキングブラインド。セキュリティとプライバシー（SP）、2014 IEEEシンポジウム。IEEE、227–242。[6] Franois Chollet。2015.ケラス。h ps：//github.com/fchollet/keras。（2015）。[オンライン;2017年5月8日アクセス]。[7]マルチェロチンクエ、ドメニココトロネオ、アントニオペッキア。2013。イベントログソフトウェア障害の分析：ルールベースのアプローチ。IEEEトランザクションソウェアエンジニアリング（TSE）（2013）、806–821。
14ページ
[8] Andrew M Daiおよびoc V Le。2015.半教師ありシーケンス学習。手続き中神経情報処理システム会議（NIPS）。3079〜3087。[9] Min DuとFeifei Li。2016.スペル：システムイベントログのストリーミング解析。に手続き IEEEデータマイニング国際会議（ICDM）。859〜864。[10]ミンドゥとフェイフェイリー。2017. ATOM：効率的な追跡、監視、オーケストラ-クラウドリソースの管理。並列および分散システムでのIEEEトランザクション（2017）。[11]強風、建光楼、李王、江李。2009.実行異常非構造化ログ分析による分散システムでの検出。手続き中 IEEEデータマイニング（ICDM）に関する国際会議。149–158。[12]ヨーブ・ゴールドバーグ。2016.自然言語のニューラルネットワークモデル入門処理。Journal of Arti cial Intelligence Research 57（2016）、345–420。[13]イアン・グッドフェロー、ヨシュア・ベンジオ、およびアーロン・クールビル。2016年。ディープラーニング。MIT押す。hp：//www.deeplearningbook.org。[14] Hossein Hamooni、Biplob Debnath、Jianwu Xu、Hui Zhang、Guofei Jiang、アブドラ・ミューン。2016. LogMine：Log Analyticsの高速認識。に手続き 情報と知識の管理に関する会議（CIKM）。1573–1582。[15]スティーブンEハンセンとEトッドアトキンス。1993.自動システム監視とスウォッチでの通知。大規模インストールシステム管理会議（LISA）。145–152。[16]ピンジア・ヘ、ジエミング・チュー、シーリン・ヘ、ジアン・リー、マイケル・リュー。2016。評価ログ解析とログマイニングにおけるその使用に関する研究。手続き中 国際会議Dependable Systems and Networks（DSN）654–661。[17] Shilin He、Jieming Zhu、Pinjia He、Michael R Lyu。2016.体験レポート：異常検出のためのシステムログ分析。手続き中 国際シンポジウムソフトウェア信頼性エンジニアリング（ISSRE）について。207–218。[18] Sepp HochreiterおよびJürgenSchmidhuber。1997.長期短期記憶。ニューラル計算（1997）、1735–1780。[19] Qingwei Lin、Hongyu Zhang、Jian-Guang Lou、Yu Zhang、Xuewei Chen。2016.オンラインサービスシステムのログクラスタリングベースの問題識別。に手続き ソフトウェア工学に関する国際会議（ICSE）。102〜111。[20] Chaochun Liu、Huan Sun、Nan Du、Shulong Tan、Hongliang Fei、Wei Fan、Taoヤン、ハオ・ウー、ヤリアン・リー、チェンウェイ・チャン。2016. Augmented LSTM Frame-医療用自己診断Androidの構築に取り組みます。手続き中 IEEEインターナショナルデータマイニング（ICDM）に関する会議。251–260。[21]建光楼、強風、盛秋陽、江李、および濱呉。2010.鉱業プログラムはインターリーブされたトレースから機能します。手続き中 ACM SIGKDDインターナショナル知識発見およびデータマイニング（SIGKDD）に関する会議。[22] Jian-Guang Lou、Qiang Fu、Shengqi Yang、Ye Xu、Jiang Li。2010.鉱業システムの問題を検出するためのコンソールログからの不変式 USENIX年次技術会議（ATC）。231–244。[23]アデトクンボAOマカンジュ、ヌルジンシルヘイウッド、エヴァンゲロスEミリオス。2009.反復パーティショニングを使用したイベントログのクラスタリング。手続き中 ACM SIGKDD知識発見とデータマイニングに関する国際会議（SIGKDD）。1255〜1264。[24]クリストファー・D・マニングとヒンリッヒ・シュツェ。1999年。統計の基礎自然言語処理。MIT Press。[25]トマス・ミコロフ、マーティン・カラ・アット、ルーカス・バーゲット、ヤン・チェルノッキー、およびサンジーブ・クーダンプール。2010.再帰型ニューラルネットワークベースの言語モデル。Interspeechでは、巻。2. 3。[26]カーシック・ナガラジ、チャールズ・キリアン、ジェニファー・ネヴィル。2012.構造化比較パフォーマンスの問題を診断するためのシステムログの積極的な分析。手続き中 USENIXネットワーク化されたシステムの設計と実装に関するシンポジウム（NSDI）。26–26。[27]クリストファー・オラー。2015. LSTMネットワークを理解する。（2015）。hp：// colah。github.io/posts/2015-08-Understanding-LSTMs [オンライン; 2017年5月16日アクセス]。[28]アリナ・オプレア、周李、ティン・ファン・イェン、サン・H・チン、スマヤ・アルワイス。2015。大規模なログデータをマイニングすることで、企業の初期段階の感染を検出します。に手続き ディペンダブルシステムとネットワークに関する国際会議（DSN）。45〜56。[29]ジェームズEプレウェ。2003. Logsurferを使用してクラスターログファイルを分析する。手続き中 年次Linuxクラスターに関する会議。[30] Robert Ricci、Eric Eide、e CloudLabチーム。2014. CloudLabの紹介：クラウドアーキテクチャとアプリケーションを進化させる科学インフラストラクチャ。USENIX;ログイン：39、6（2014年12月）。h ps：//www.usenix.org/publications/login/dec14 / ricci[31]ジョンPルーイヤール。2004.シンプルイベントを使用したリアルタイムログファイル分析コリレータ（SEC）。Proc。大規模インストールシステム管理会議（LISA）。133–150。[32] Sudip Roy、Arnd ChristianKönig、Igor Dvorkin、およびManish Kumar。2015。faugur：クラウドサービスのパフォーマンスの異常に対する堅牢な診断。手続き中IEEE国際データエンジニアリング会議（ICDE）。IEEE、1167〜1178。[33]エラスティックスタック。2017. eオープンソースのElastic Stack。（2017）。h ps：//www.elastic。共同/製品 [オンライン; 2017年5月16日アクセス]。マーティン・サンダーマイヤー、ラルフ・シュリューター、ヘルマン・ネイ。2012. LSTMニューラル言語モデリングのためのネットワーク..インタースピーチ。194–197。[35]イリヤ・サツケバー、オリオール・ヴィンヤルス、oc V Le。2014.シーケンスからシーケンスへの学習ニューラルネットワークで。手続き中 神経情報処理システム会議（NIPS）。3104–3112。[36] Liang TangおよびTao Li。2010. LogTree：システムを生成するためのフレームワーク生のテキストログからのイベント。手続き中 IEEEデータ国際会議マイニング（ICDM）。491–500。[37] Liang Tang、Tao Li、およびChang-Shing Perng。2011. LogSig：生成システム生のテキストログからのイベント。手続き中 情報と知識に関する会議管理（CIKM）。785-794。[38]徐徐、玲黄、アルマンドフォックス、デビッドパーソン、マイケルジョーダン。2009。コンソールログの一部をマイニングすることによるオンラインシステム問題検出。手続き中IEEEデータマイニング国際会議（ICDM）。588〜597。[39]徐徐、玲黄、アルマンドフォックス、デビッドパーパーソン、マイケルIジョーダン。2009。コンソールログをマイニングして大規模システムの問題を検出します。手続き中 ACMオペレーティングシステム原則（SOSP）に関するシンポジウム。117–132。[40]山西賢治と丸山優子。2015.ネットワークの動的syslogマイニング障害監視。手続き中 ACM SIGKDD知識に関する国際会議発見とデータマイニング（SIGKDD）。499〜508。[41] Ting-Fang Yen、Alina Oprea、Kaan Onarlioglu、Todd Leetham、William Robertson、アリ・ジュエルス、そしてエンギン・キルダ。2013. Beehive：検出のための大規模なログ分析エンタープライズネットワークでの不審なアクティビティ。手続き中 国際会議Dependable Systems and Networks（ACSAC）。199–208。[42] Xiao Yu、Pallavi Joshi、Jianwu Xu、Guolian Jin、Hui Zhang、およびGuofei Jiang。2016。CloudSeer：インターリーブされたログを介したクラウドインフラストラクチャのワークフロー監視。手続き中 プログラミングのアーキテクチャサポートに関するACM国際会議言語とオペレーティングシステム（ASPLOS）。489–502。[43]ディンユアン、ハオフイマイ、ウェイウェイシオン、リンタン、ユアンユエンチョウ、シャンカールパスパシー。2010. SherLog：ランタイムからの手がかりを接続することによるエラー診断ログ。ACM SIGARCHコンピュータアーキテクチャニュース。ACM、143–154。[44] Ke Zhang、Jianwu Xu、Martin Renqiang Min、Guofei Jiang、Konstantinos Pelechri-nis、およびHui Zhang。2016. ITシステム障害の自動予測：深い学習アプローチ。手続き中 ビッグデータに関するIEEE国際会議（IEEE BigData）。1291〜1300。[45]徐趙、カーク・ロドリゲス、遊羅、丁元、マイケル・スタム。2016。owに基づくソフトウェアスタック全体の侵入型パフォーマンスプロファイリング再建の原則。手続き中 オペレーティングシステム設計に関するUSENIXシンポジウムおよび実装（OSDI）。603–618。
